{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# RVFL on Breast Cancer dataset with hyperparameter tuning\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load and preprocess Breast Cancer dataset\n",
        "print(\"Loading Breast Cancer dataset...\")\n",
        "data = load_breast_cancer()\n",
        "X = StandardScaler().fit_transform(data.data)\n",
        "y = data.target\n",
        "y_onehot = np.eye(2)[y]  # One-hot encoding\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameter settings\n",
        "hidden_nodes_list = [10, 20, 30]\n",
        "activation_functions = {'sigmoid': sigmoid, 'tanh': tanh}\n",
        "\n",
        "best_config = {}\n",
        "best_test_acc = 0\n",
        "\n",
        "print(\"Starting hyperparameter tuning...\\n\")\n",
        "\n",
        "for act_name, act_func in activation_functions.items():\n",
        "    for n_hidden in hidden_nodes_list:\n",
        "        input_size = X.shape[1]\n",
        "        W = np.random.randn(n_hidden, input_size)\n",
        "        b = np.random.randn(n_hidden)\n",
        "\n",
        "        def compute_H(X):\n",
        "            H = act_func(np.dot(X, W.T) + b)\n",
        "            return np.hstack([H, X])  # Concatenate hidden layer output and input\n",
        "\n",
        "        # Train\n",
        "        start_train = time.time()\n",
        "        H_train = compute_H(X_train)\n",
        "        output_weights = np.linalg.pinv(H_train) @ y_train\n",
        "        end_train = time.time()\n",
        "\n",
        "        # Predict on training data\n",
        "        y_train_pred = H_train @ output_weights\n",
        "        train_pred_labels = np.argmax(y_train_pred, axis=1)\n",
        "        train_true_labels = np.argmax(y_train, axis=1)\n",
        "        train_acc = accuracy_score(train_true_labels, train_pred_labels)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "        # Predict on test data\n",
        "        start_test = time.time()\n",
        "        H_test = compute_H(X_test)\n",
        "        y_test_pred = H_test @ output_weights\n",
        "        end_test = time.time()\n",
        "\n",
        "        test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "        test_true_labels = np.argmax(y_test, axis=1)\n",
        "        test_acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "        print(f\"[{act_name}] Hidden={n_hidden} | TrainAcc={train_acc:.4f} TestAcc={test_acc:.4f} | TrainRMSE={train_rmse:.4f} TestRMSE={test_rmse:.4f}\")\n",
        "\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            best_config = {\n",
        "                'activation': act_name,\n",
        "                'n_hidden': n_hidden,\n",
        "                'train_acc': train_acc,\n",
        "                'test_acc': test_acc,\n",
        "                'train_rmse': train_rmse,\n",
        "                'test_rmse': test_rmse,\n",
        "                'train_time': end_train - start_train,\n",
        "                'test_time': end_test - start_test\n",
        "            }\n",
        "\n",
        "# Print best result\n",
        "print(\"\\nBest Configuration:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjaWo99nCkMr",
        "outputId": "a52f9b2c-de74-4ec8-d146-6a2b98a08155"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset...\n",
            "Starting hyperparameter tuning...\n",
            "\n",
            "[sigmoid] Hidden=10 | TrainAcc=0.9670 TestAcc=0.9649 | TrainRMSE=0.2202 TestRMSE=0.2392\n",
            "[sigmoid] Hidden=20 | TrainAcc=0.9846 TestAcc=0.9561 | TrainRMSE=0.1994 TestRMSE=0.2359\n",
            "[sigmoid] Hidden=30 | TrainAcc=0.9648 TestAcc=0.9386 | TrainRMSE=0.1985 TestRMSE=0.2390\n",
            "[tanh] Hidden=10 | TrainAcc=0.9714 TestAcc=0.9474 | TrainRMSE=0.3168 TestRMSE=0.3432\n",
            "[tanh] Hidden=20 | TrainAcc=0.9802 TestAcc=0.9474 | TrainRMSE=0.2520 TestRMSE=0.2965\n",
            "[tanh] Hidden=30 | TrainAcc=0.9802 TestAcc=0.9649 | TrainRMSE=0.2283 TestRMSE=0.2348\n",
            "\n",
            "Best Configuration:\n",
            "activation: sigmoid\n",
            "n_hidden: 10\n",
            "train_acc: 0.967032967032967\n",
            "test_acc: 0.9649122807017544\n",
            "train_rmse: 0.22018349337845936\n",
            "test_rmse: 0.2391559513473764\n",
            "train_time: 0.0026183128356933594\n",
            "test_time: 0.0002033710479736328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deepRVFL on Breast Cancer dataset with hyperparameter tuning\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "print(\"Loading Breast Cancer dataset...\")\n",
        "data = load_breast_cancer()\n",
        "X = StandardScaler().fit_transform(data.data)\n",
        "y = data.target\n",
        "y_onehot = np.eye(2)[y]  # One-hot encoding for binary classification\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "depth_list = [2, 3]\n",
        "hidden_nodes_list = [10, 20]\n",
        "activation_functions = {'sigmoid': sigmoid, 'tanh': tanh}\n",
        "lambda_ridge = 1e-3\n",
        "\n",
        "best_config = {}\n",
        "best_test_acc = 0\n",
        "\n",
        "print(\"\\nStarting Deep RVFL tuning...\\n\")\n",
        "\n",
        "for act_name, act_func in activation_functions.items():\n",
        "    for depth in depth_list:\n",
        "        for n_hidden in hidden_nodes_list:\n",
        "            input_size = X.shape[1]\n",
        "            Ws, bs = [], []\n",
        "            np.random.seed(42)\n",
        "\n",
        "            current_input_size = input_size\n",
        "            for _ in range(depth):\n",
        "                W = np.random.randn(n_hidden, current_input_size)\n",
        "                b = np.random.randn(n_hidden)\n",
        "                Ws.append(W)\n",
        "                bs.append(b)\n",
        "                current_input_size += n_hidden\n",
        "\n",
        "            def compute_deep_H(X_input):\n",
        "                concat_features = X_input\n",
        "                for l in range(depth):\n",
        "                    H = act_func(np.dot(concat_features, Ws[l].T) + bs[l])\n",
        "                    concat_features = np.hstack([concat_features, H])\n",
        "                return concat_features\n",
        "\n",
        "            # Train\n",
        "            start_train = time.time()\n",
        "            H_train = compute_deep_H(X_train)\n",
        "            I = np.identity(H_train.shape[1])\n",
        "            output_weights = np.linalg.inv(H_train.T @ H_train + lambda_ridge * I) @ H_train.T @ y_train\n",
        "            end_train = time.time()\n",
        "\n",
        "            y_train_pred = H_train @ output_weights\n",
        "            train_true_labels = np.argmax(y_train, axis=1)\n",
        "            train_pred_labels = np.argmax(y_train_pred, axis=1)\n",
        "            train_acc = accuracy_score(train_true_labels, train_pred_labels)\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "            # Test\n",
        "            start_test = time.time()\n",
        "            H_test = compute_deep_H(X_test)\n",
        "            y_test_pred = H_test @ output_weights\n",
        "            end_test = time.time()\n",
        "\n",
        "            test_true_labels = np.argmax(y_test, axis=1)\n",
        "            test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "            test_acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "            print(f\"[{act_name}] Depth={depth} Hidden={n_hidden} | TrainAcc={train_acc:.4f} TestAcc={test_acc:.4f} | TrainRMSE={train_rmse:.4f} TestRMSE={test_rmse:.4f}\")\n",
        "\n",
        "            if test_acc > best_test_acc:\n",
        "                best_test_acc = test_acc\n",
        "                best_config = {\n",
        "                    'activation': act_name,\n",
        "                    'depth': depth,\n",
        "                    'n_hidden': n_hidden,\n",
        "                    'train_acc': train_acc,\n",
        "                    'test_acc': test_acc,\n",
        "                    'train_rmse': train_rmse,\n",
        "                    'test_rmse': test_rmse,\n",
        "                    'train_time': end_train - start_train,\n",
        "                    'test_time': end_test - start_test\n",
        "                }\n",
        "\n",
        "# Print best configuration\n",
        "print(\"\\nBest Deep RVFL Configuration:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnsU747AC9ke",
        "outputId": "6ccaa279-7b69-4b42-f93e-e5e357d7ce25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset...\n",
            "\n",
            "Starting Deep RVFL tuning...\n",
            "\n",
            "[sigmoid] Depth=2 Hidden=10 | TrainAcc=0.9736 TestAcc=0.9737 | TrainRMSE=0.1952 TestRMSE=0.2103\n",
            "[sigmoid] Depth=2 Hidden=20 | TrainAcc=0.9780 TestAcc=0.9474 | TrainRMSE=0.1811 TestRMSE=0.2308\n",
            "[sigmoid] Depth=3 Hidden=10 | TrainAcc=0.9758 TestAcc=0.9561 | TrainRMSE=0.1908 TestRMSE=0.2125\n",
            "[sigmoid] Depth=3 Hidden=20 | TrainAcc=0.9824 TestAcc=0.9386 | TrainRMSE=0.1683 TestRMSE=0.2317\n",
            "[tanh] Depth=2 Hidden=10 | TrainAcc=0.9692 TestAcc=0.9561 | TrainRMSE=0.3711 TestRMSE=0.3909\n",
            "[tanh] Depth=2 Hidden=20 | TrainAcc=0.9780 TestAcc=0.9474 | TrainRMSE=0.2419 TestRMSE=0.3049\n",
            "[tanh] Depth=3 Hidden=10 | TrainAcc=0.9648 TestAcc=0.9737 | TrainRMSE=0.3357 TestRMSE=0.3499\n",
            "[tanh] Depth=3 Hidden=20 | TrainAcc=0.9824 TestAcc=0.9474 | TrainRMSE=0.2272 TestRMSE=0.2897\n",
            "\n",
            "Best Deep RVFL Configuration:\n",
            "activation: sigmoid\n",
            "depth: 2\n",
            "n_hidden: 10\n",
            "train_acc: 0.9736263736263736\n",
            "test_acc: 0.9736842105263158\n",
            "train_rmse: 0.19522344006276332\n",
            "test_rmse: 0.21025921098091901\n",
            "train_time: 0.0009770393371582031\n",
            "test_time: 0.00022649765014648438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ensembledeepRVFL on Breast Cancer dataset with hyperparameter tuning\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "print(\"Loading Breast Cancer dataset...\")\n",
        "data = load_breast_cancer()\n",
        "X = StandardScaler().fit_transform(data.data)\n",
        "y = data.target\n",
        "y_onehot = np.eye(2)[y]  # One-hot encode labels for binary classification\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "depth_list = [2, 3]\n",
        "hidden_nodes_list = [10, 20]\n",
        "activation_functions = {'sigmoid': sigmoid, 'tanh': tanh}\n",
        "lambda_ridge = 1e-3\n",
        "\n",
        "best_config = {}\n",
        "best_test_acc = 0\n",
        "\n",
        "print(\"\\nStarting ensemble DRVFL tuning...\\n\")\n",
        "\n",
        "for act_name, act_func in activation_functions.items():\n",
        "    for depth in depth_list:\n",
        "        for n_hidden in hidden_nodes_list:\n",
        "            input_size = X.shape[1]\n",
        "            Ws, bs = [], []\n",
        "            np.random.seed(42)\n",
        "\n",
        "            current_input_size = input_size\n",
        "            for _ in range(depth):\n",
        "                W = np.random.randn(n_hidden, current_input_size)\n",
        "                b = np.random.randn(n_hidden)\n",
        "                Ws.append(W)\n",
        "                bs.append(b)\n",
        "                current_input_size += n_hidden\n",
        "\n",
        "            def layer_forward(X_input, W, b):\n",
        "                H = act_func(np.dot(X_input, W.T) + b)\n",
        "                return np.hstack([X_input, H])\n",
        "\n",
        "            # Train\n",
        "            start_train = time.time()\n",
        "            layer_outputs_train = []\n",
        "            current_input = X_train.copy()\n",
        "\n",
        "            for l in range(depth):\n",
        "                H = layer_forward(current_input, Ws[l], bs[l])\n",
        "                current_input = H\n",
        "                I = np.identity(H.shape[1])\n",
        "                beta = np.linalg.inv(H.T @ H + lambda_ridge * I) @ H.T @ y_train\n",
        "                layer_outputs_train.append((H, beta))\n",
        "\n",
        "            end_train = time.time()\n",
        "\n",
        "            # Ensemble training prediction\n",
        "            y_train_preds = [H @ beta for H, beta in layer_outputs_train]\n",
        "            y_train_ensemble = np.mean(y_train_preds, axis=0)\n",
        "            train_pred_labels = np.argmax(y_train_ensemble, axis=1)\n",
        "            train_true_labels = np.argmax(y_train, axis=1)\n",
        "            train_acc = accuracy_score(train_true_labels, train_pred_labels)\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_ensemble))\n",
        "\n",
        "            # Test\n",
        "            start_test = time.time()\n",
        "            layer_outputs_test = []\n",
        "            current_input = X_test.copy()\n",
        "\n",
        "            for l in range(depth):\n",
        "                H_test = layer_forward(current_input, Ws[l], bs[l])\n",
        "                current_input = H_test\n",
        "                _, beta = layer_outputs_train[l]\n",
        "                pred_test = H_test @ beta\n",
        "                layer_outputs_test.append(pred_test)\n",
        "\n",
        "            y_test_ensemble = np.mean(layer_outputs_test, axis=0)\n",
        "            end_test = time.time()\n",
        "\n",
        "            test_pred_labels = np.argmax(y_test_ensemble, axis=1)\n",
        "            test_true_labels = np.argmax(y_test, axis=1)\n",
        "            test_acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_ensemble))\n",
        "\n",
        "            print(f\"[{act_name}] Depth={depth} Hidden={n_hidden} | TrainAcc={train_acc:.4f} TestAcc={test_acc:.4f} | TrainRMSE={train_rmse:.4f} TestRMSE={test_rmse:.4f}\")\n",
        "\n",
        "            if test_acc > best_test_acc:\n",
        "                best_test_acc = test_acc\n",
        "                best_config = {\n",
        "                    'activation': act_name,\n",
        "                    'depth': depth,\n",
        "                    'n_hidden': n_hidden,\n",
        "                    'train_acc': train_acc,\n",
        "                    'test_acc': test_acc,\n",
        "                    'train_rmse': train_rmse,\n",
        "                    'test_rmse': test_rmse,\n",
        "                    'train_time': end_train - start_train,\n",
        "                    'test_time': end_test - start_test\n",
        "                }\n",
        "\n",
        "# Print best configuration\n",
        "print(\"\\nBest Ensemble DRVFL Configuration:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FnkaBocDnaa",
        "outputId": "588ead45-40df-4376-b413-80a0ad09d97f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset...\n",
            "\n",
            "Starting ensemble DRVFL tuning...\n",
            "\n",
            "[sigmoid] Depth=2 Hidden=10 | TrainAcc=0.9758 TestAcc=0.9649 | TrainRMSE=0.1990 TestRMSE=0.2140\n",
            "[sigmoid] Depth=2 Hidden=20 | TrainAcc=0.9780 TestAcc=0.9474 | TrainRMSE=0.1852 TestRMSE=0.2263\n",
            "[sigmoid] Depth=3 Hidden=10 | TrainAcc=0.9736 TestAcc=0.9649 | TrainRMSE=0.1945 TestRMSE=0.2111\n",
            "[sigmoid] Depth=3 Hidden=20 | TrainAcc=0.9780 TestAcc=0.9474 | TrainRMSE=0.1760 TestRMSE=0.2227\n",
            "[tanh] Depth=2 Hidden=10 | TrainAcc=0.9670 TestAcc=0.9649 | TrainRMSE=0.3756 TestRMSE=0.3977\n",
            "[tanh] Depth=2 Hidden=20 | TrainAcc=0.9802 TestAcc=0.9298 | TrainRMSE=0.2468 TestRMSE=0.3072\n",
            "[tanh] Depth=3 Hidden=10 | TrainAcc=0.9670 TestAcc=0.9649 | TrainRMSE=0.3540 TestRMSE=0.3709\n",
            "[tanh] Depth=3 Hidden=20 | TrainAcc=0.9824 TestAcc=0.9386 | TrainRMSE=0.2361 TestRMSE=0.2959\n",
            "\n",
            "Best Ensemble DRVFL Configuration:\n",
            "activation: sigmoid\n",
            "depth: 2\n",
            "n_hidden: 10\n",
            "train_acc: 0.9758241758241758\n",
            "test_acc: 0.9649122807017544\n",
            "train_rmse: 0.199012804636247\n",
            "test_rmse: 0.21400354550170128\n",
            "train_time: 0.0014753341674804688\n",
            "test_time: 0.0004646778106689453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RVFL on MNIST dataset with hyperparameter tuning\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load MNIST dataset\n",
        "print(\"Loading MNIST dataset...\")\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
        "X = X / 255.0  # Normalize pixel values to [0, 1]\n",
        "y = y.astype(int)\n",
        "y_onehot = np.eye(10)[y]  # One-hot encode labels\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameter settings\n",
        "hidden_nodes_list = [10, 20, 30]\n",
        "activation_functions = {'sigmoid': sigmoid, 'tanh': tanh}\n",
        "\n",
        "best_config = {}\n",
        "best_test_acc = 0\n",
        "\n",
        "print(\"Starting hyperparameter tuning...\\n\")\n",
        "\n",
        "for act_name, act_func in activation_functions.items():\n",
        "    for n_hidden in hidden_nodes_list:\n",
        "        input_size = X.shape[1]\n",
        "        W = np.random.randn(n_hidden, input_size)\n",
        "        b = np.random.randn(n_hidden)\n",
        "\n",
        "        def compute_H(X):\n",
        "            H = act_func(np.dot(X, W.T) + b)\n",
        "            return np.hstack([H, X])  # Concatenate hidden layer output and input\n",
        "\n",
        "        # Train\n",
        "        start_train = time.time()\n",
        "        H_train = compute_H(X_train)\n",
        "        output_weights = np.linalg.pinv(H_train) @ y_train\n",
        "        end_train = time.time()\n",
        "\n",
        "        # Predict on training data\n",
        "        y_train_pred = H_train @ output_weights\n",
        "        train_pred_labels = np.argmax(y_train_pred, axis=1)\n",
        "        train_true_labels = np.argmax(y_train, axis=1)\n",
        "        train_acc = accuracy_score(train_true_labels, train_pred_labels)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "        # Predict on test data\n",
        "        start_test = time.time()\n",
        "        H_test = compute_H(X_test)\n",
        "        y_test_pred = H_test @ output_weights\n",
        "        end_test = time.time()\n",
        "\n",
        "        test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "        test_true_labels = np.argmax(y_test, axis=1)\n",
        "        test_acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "        print(f\"[{act_name}] Hidden={n_hidden} | TrainAcc={train_acc:.4f} TestAcc={test_acc:.4f} | TrainRMSE={train_rmse:.4f} TestRMSE={test_rmse:.4f}\")\n",
        "\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            best_config = {\n",
        "                'activation': act_name,\n",
        "                'n_hidden': n_hidden,\n",
        "                'train_acc': train_acc,\n",
        "                'test_acc': test_acc,\n",
        "                'train_rmse': train_rmse,\n",
        "                'test_rmse': test_rmse,\n",
        "                'train_time': end_train - start_train,\n",
        "                'test_time': end_test - start_test\n",
        "            }\n",
        "\n",
        "# Print best result\n",
        "print(\"\\nBest Configuration:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72373be6-f622-47ca-c74d-e056ca4e8dfb",
        "id": "kKkoE_6qFI65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST dataset...\n",
            "Starting hyperparameter tuning...\n",
            "\n",
            "[sigmoid] Hidden=10 | TrainAcc=0.8616 TestAcc=0.8544 | TrainRMSE=0.1941 TestRMSE=0.1979\n",
            "[sigmoid] Hidden=20 | TrainAcc=0.8666 TestAcc=0.8581 | TrainRMSE=0.1924 TestRMSE=0.1960\n",
            "[sigmoid] Hidden=30 | TrainAcc=0.8672 TestAcc=0.8589 | TrainRMSE=0.1919 TestRMSE=0.1956\n",
            "[tanh] Hidden=10 | TrainAcc=0.8568 TestAcc=0.8506 | TrainRMSE=0.1961 TestRMSE=0.1999\n",
            "[tanh] Hidden=20 | TrainAcc=0.8616 TestAcc=0.8562 | TrainRMSE=0.1942 TestRMSE=0.1979\n",
            "[tanh] Hidden=30 | TrainAcc=0.8653 TestAcc=0.8586 | TrainRMSE=0.1926 TestRMSE=0.1962\n",
            "\n",
            "Best Configuration:\n",
            "activation: sigmoid\n",
            "n_hidden: 30\n",
            "train_acc: 0.8672142857142857\n",
            "test_acc: 0.8589285714285714\n",
            "train_rmse: 0.1918564836498676\n",
            "test_rmse: 0.19559669185177567\n",
            "train_time: 20.80580759048462\n",
            "test_time: 0.11172723770141602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deepRVFL on MNIST dataset with hyperparameter tuning\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load MNIST dataset\n",
        "print(\"Loading MNIST...\")\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
        "X = X / 255.0\n",
        "y = y.astype(int)\n",
        "y_onehot = np.eye(10)[y]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "depth_list = [2, 3]\n",
        "hidden_nodes_list = [10, 20]\n",
        "activation_functions = {'sigmoid': sigmoid, 'tanh': tanh}\n",
        "lambda_ridge = 1e-3\n",
        "\n",
        "best_config = {}\n",
        "best_test_acc = 0\n",
        "\n",
        "print(\"\\nStarting Deep RVFL tuning...\\n\")\n",
        "\n",
        "for act_name, act_func in activation_functions.items():\n",
        "    for depth in depth_list:\n",
        "        for n_hidden in hidden_nodes_list:\n",
        "            input_size = X.shape[1]\n",
        "            Ws, bs = [], []\n",
        "            np.random.seed(42)\n",
        "\n",
        "            # Update input size for each layer\n",
        "            current_input_size = input_size\n",
        "            for _ in range(depth):\n",
        "                W = np.random.randn(n_hidden, current_input_size)\n",
        "                b = np.random.randn(n_hidden)\n",
        "                Ws.append(W)\n",
        "                bs.append(b)\n",
        "                current_input_size += n_hidden  # Because of concatenation\n",
        "\n",
        "            def compute_deep_H(X_input):\n",
        "                concat_features = X_input\n",
        "                for l in range(depth):\n",
        "                    H = act_func(np.dot(concat_features, Ws[l].T) + bs[l])\n",
        "                    concat_features = np.hstack([concat_features, H])\n",
        "                return concat_features\n",
        "\n",
        "            # Train\n",
        "            start_train = time.time()\n",
        "            H_train = compute_deep_H(X_train)\n",
        "            I = np.identity(H_train.shape[1])\n",
        "            output_weights = np.linalg.inv(H_train.T @ H_train + lambda_ridge * I) @ H_train.T @ y_train\n",
        "            end_train = time.time()\n",
        "\n",
        "            # Train predictions\n",
        "            y_train_pred = H_train @ output_weights\n",
        "            train_true_labels = np.argmax(y_train, axis=1)\n",
        "            train_pred_labels = np.argmax(y_train_pred, axis=1)\n",
        "            train_acc = accuracy_score(train_true_labels, train_pred_labels)\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "            # Test\n",
        "            start_test = time.time()\n",
        "            H_test = compute_deep_H(X_test)\n",
        "            y_test_pred = H_test @ output_weights\n",
        "            end_test = time.time()\n",
        "\n",
        "            test_true_labels = np.argmax(y_test, axis=1)\n",
        "            test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "            test_acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "            print(f\"[{act_name}] Depth={depth} Hidden={n_hidden} | TrainAcc={train_acc:.4f} TestAcc={test_acc:.4f}\")\n",
        "\n",
        "            if test_acc > best_test_acc:\n",
        "                best_test_acc = test_acc\n",
        "                best_config = {\n",
        "                    'activation': act_name,\n",
        "                    'depth': depth,\n",
        "                    'n_hidden': n_hidden,\n",
        "                    'train_acc': train_acc,\n",
        "                    'test_acc': test_acc,\n",
        "                    'train_rmse': train_rmse,\n",
        "                    'test_rmse': test_rmse,\n",
        "                    'train_time': end_train - start_train,\n",
        "                    'test_time': end_test - start_test\n",
        "                }\n",
        "\n",
        "# Print best configuration\n",
        "print(\"\\nBest Deep RVFL Configuration:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NqA1ldmHta",
        "outputId": "bbbc50c0-f111-463e-c812-79733417a924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST...\n",
            "\n",
            "Starting Deep RVFL tuning...\n",
            "\n",
            "[sigmoid] Depth=2 Hidden=10 | TrainAcc=0.8635 TestAcc=0.8582\n",
            "[sigmoid] Depth=2 Hidden=20 | TrainAcc=0.8717 TestAcc=0.8672\n",
            "[sigmoid] Depth=3 Hidden=10 | TrainAcc=0.8664 TestAcc=0.8601\n",
            "[sigmoid] Depth=3 Hidden=20 | TrainAcc=0.8758 TestAcc=0.8699\n",
            "[tanh] Depth=2 Hidden=10 | TrainAcc=0.8612 TestAcc=0.8566\n",
            "[tanh] Depth=2 Hidden=20 | TrainAcc=0.8676 TestAcc=0.8644\n",
            "[tanh] Depth=3 Hidden=10 | TrainAcc=0.8626 TestAcc=0.8563\n",
            "[tanh] Depth=3 Hidden=20 | TrainAcc=0.8703 TestAcc=0.8665\n",
            "\n",
            "Best Deep RVFL Configuration:\n",
            "activation: sigmoid\n",
            "depth: 3\n",
            "n_hidden: 20\n",
            "train_acc: 0.8757857142857143\n",
            "test_acc: 0.8698571428571429\n",
            "train_rmse: 0.18754425184958304\n",
            "test_rmse: 0.19025904332080093\n",
            "train_time: 5.361662864685059\n",
            "test_time: 0.38353872299194336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ensembledeepRVFL on MNIST dataset with hyperparameter tuning\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Load MNIST\n",
        "print(\"Loading MNIST...\")\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
        "X = X / 255.0\n",
        "y = y.astype(int)\n",
        "y_onehot = np.eye(10)[y]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "depth_list = [2, 3]\n",
        "hidden_nodes_list = [10, 20]\n",
        "activation_functions = {'sigmoid': sigmoid, 'tanh': tanh}\n",
        "lambda_ridge = 1e-3\n",
        "\n",
        "best_config = {}\n",
        "best_test_acc = 0\n",
        "\n",
        "print(\"\\nStarting ensemble DRVFL tuning...\\n\")\n",
        "\n",
        "for act_name, act_func in activation_functions.items():\n",
        "    for depth in depth_list:\n",
        "        for n_hidden in hidden_nodes_list:\n",
        "            input_size = X.shape[1]\n",
        "            Ws, bs = [], []\n",
        "            np.random.seed(42)\n",
        "\n",
        "            # Dynamically increase input dimension at each layer\n",
        "            current_input_size = input_size\n",
        "            for _ in range(depth):\n",
        "                W = np.random.randn(n_hidden, current_input_size)\n",
        "                b = np.random.randn(n_hidden)\n",
        "                Ws.append(W)\n",
        "                bs.append(b)\n",
        "                current_input_size += n_hidden\n",
        "\n",
        "            def layer_forward(X_input, W, b):\n",
        "                H = act_func(np.dot(X_input, W.T) + b)\n",
        "                return np.hstack([X_input, H])\n",
        "\n",
        "            # Train\n",
        "            start_train = time.time()\n",
        "            layer_outputs_train = []\n",
        "            current_input = X_train.copy()\n",
        "\n",
        "            for l in range(depth):\n",
        "                H = layer_forward(current_input, Ws[l], bs[l])\n",
        "                current_input = H\n",
        "                I = np.identity(H.shape[1])\n",
        "                beta = np.linalg.inv(H.T @ H + lambda_ridge * I) @ H.T @ y_train\n",
        "                layer_outputs_train.append((H, beta))\n",
        "\n",
        "            end_train = time.time()\n",
        "\n",
        "            # Ensemble prediction on training set\n",
        "            y_train_preds = [H @ beta for H, beta in layer_outputs_train]\n",
        "            y_train_ensemble = np.mean(y_train_preds, axis=0)\n",
        "            train_pred_labels = np.argmax(y_train_ensemble, axis=1)\n",
        "            train_true_labels = np.argmax(y_train, axis=1)\n",
        "            train_acc = accuracy_score(train_true_labels, train_pred_labels)\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_ensemble))\n",
        "\n",
        "            # Test\n",
        "            start_test = time.time()\n",
        "            layer_outputs_test = []\n",
        "            current_input = X_test.copy()\n",
        "\n",
        "            for l in range(depth):\n",
        "                H_test = layer_forward(current_input, Ws[l], bs[l])\n",
        "                current_input = H_test\n",
        "                _, beta = layer_outputs_train[l]\n",
        "                pred_test = H_test @ beta\n",
        "                layer_outputs_test.append(pred_test)\n",
        "\n",
        "            y_test_ensemble = np.mean(layer_outputs_test, axis=0)\n",
        "            end_test = time.time()\n",
        "\n",
        "            test_pred_labels = np.argmax(y_test_ensemble, axis=1)\n",
        "            test_true_labels = np.argmax(y_test, axis=1)\n",
        "            test_acc = accuracy_score(test_true_labels, test_pred_labels)\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_ensemble))\n",
        "\n",
        "            print(f\"[{act_name}] Depth={depth} Hidden={n_hidden} | TrainAcc={train_acc:.4f} TestAcc={test_acc:.4f}\")\n",
        "\n",
        "            if test_acc > best_test_acc:\n",
        "                best_test_acc = test_acc\n",
        "                best_config = {\n",
        "                    'activation': act_name,\n",
        "                    'depth': depth,\n",
        "                    'n_hidden': n_hidden,\n",
        "                    'train_acc': train_acc,\n",
        "                    'test_acc': test_acc,\n",
        "                    'train_rmse': train_rmse,\n",
        "                    'test_rmse': test_rmse,\n",
        "                    'train_time': end_train - start_train,\n",
        "                    'test_time': end_test - start_test\n",
        "                }\n",
        "\n",
        "# Best config\n",
        "print(\"\\nBest Ensemble DRVFL Configuration:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGGQSiDcmTzC",
        "outputId": "3c25fcde-a02d-4001-abd2-a3b3cb3c741f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST...\n",
            "\n",
            "Starting ensemble DRVFL tuning...\n",
            "\n",
            "[sigmoid] Depth=2 Hidden=10 | TrainAcc=0.8628 TestAcc=0.8575\n",
            "[sigmoid] Depth=2 Hidden=20 | TrainAcc=0.8690 TestAcc=0.8645\n",
            "[sigmoid] Depth=3 Hidden=10 | TrainAcc=0.8643 TestAcc=0.8589\n",
            "[sigmoid] Depth=3 Hidden=20 | TrainAcc=0.8729 TestAcc=0.8662\n",
            "[tanh] Depth=2 Hidden=10 | TrainAcc=0.8611 TestAcc=0.8552\n",
            "[tanh] Depth=2 Hidden=20 | TrainAcc=0.8653 TestAcc=0.8599\n",
            "[tanh] Depth=3 Hidden=10 | TrainAcc=0.8617 TestAcc=0.8566\n",
            "[tanh] Depth=3 Hidden=20 | TrainAcc=0.8676 TestAcc=0.8631\n",
            "\n",
            "Best Ensemble DRVFL Configuration:\n",
            "activation: sigmoid\n",
            "depth: 3\n",
            "n_hidden: 20\n",
            "train_acc: 0.8728571428571429\n",
            "test_acc: 0.8662142857142857\n",
            "train_rmse: 0.1888222209250521\n",
            "test_rmse: 0.19157156394096436\n",
            "train_time: 15.812729835510254\n",
            "test_time: 0.5134727954864502\n"
          ]
        }
      ]
    }
  ]
}